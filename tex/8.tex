\setcounter{chapter}{7}
\chapter{Ленивые вычисления}

В этой главе мы поговорим о том как в Haskell устроено вычисление
программ. В самом начале мы говорили о том, что 
процесса вычисления значений нет. В том смысле, что у нас
нет новых значений, у нас ничего не меняется. 

Вкратце вспомним то, что мы уже знаем о вычислениях.
Сначала мы с помощью типов определяем
множество всех возможных значений. Значения -- это деревья
в узлах которых записаны конструкторы, которые мы 
определяем в типах. Так например мы можем определить тип:

\begin{code}
data Nat = Zero | Succ Nat
\end{code}

Этим типом мы определяем множество допустимых значений. 
В данном случае это цепочки конструкторов \In{Succ},
которые заканчиваются конструктором \In{Zero}:

\begin{code}
Zero, Succ Zero, Succ (Succ Zero), ...
\end{code}
    
Затем начинаем давать им
новые имена, создавая константы (простые имена-синонимы) 
  
\begin{code}
zero    = Zero
one     = Succ zero
two     = Succ one
\end{code}


\noindent и функции (составные имена-синонимы):

\begin{code}
foldNat     :: a -> (a -> a) -> Nat -> a
foldNat z  s  Zero      = z
foldNat z  s  (Succ n)  = s (foldNat z s n)

add a = foldNat a   Succ
mul a = foldNat one (add a) 
\end{code}

Затем мы передаём нашу программу на проверку компилятору. 
Мы просим у него проверить не создаём ли мы случайно 
какие-нибудь бессмысленные
выражения. Бессмысленные потому, что они пытаются 
создать значение, которое не вписывается в наши типы.
Например если мы где-нибудь попробуем составить выражение:

\begin{code}
add Zero mul
\end{code}

Компилятор напомнит нам о том, что мы пытаемся подставить
функцию \In{mul} на место обычного значения типа \In{Nat}.
Тогда мы исправим выражение на:

\begin{code}
add Zero two
\end{code}

Компилятор согласится. И передаст выражение вычислителю. 
И тут мы говорили, что вычислитель начинает проводить
расшифровку нашего описания. Он подставляет на место 
синонимов их определения, правые части из уравнений. Этот
процесс мы называли \emph{редукцией}. 
Вычислитель видит два синонима и одно значение. С какого синонима начать? 
С \In{add} или \In{two}?

\section{Стратегии вычислений}

Этот вопрос приводит нас к понятию стратегии вычислений.
Поскольку вычисляем мы только константы, то наше выражение
также можно представить в виде дерева. Только теперь у нас 
в узлах записаны не только конструкторы, но и синонимы.
Процесс редукции можно представить как процесс очистки такого
дерева от синонимов. Посмотрим на дерево нашего значения:

Оказывается у нас есть две возможности очистки синонимов.

\EmphDesc{Cнизу-вверх}{%
    \Strategy{вычисление по значению}
    начинаем с листьев и убираем все синонимы в листьях дерева 
    выражения. Как только в данном узле и всех дочерних узлах 
    остались одни конструкторы можно переходить на уровень выше. 
    Так мы поднимаемся выше и выше пока не дойдём до корня. 
}

\EmphDesc{Cверху-вниз}{%
    \Strategy{вычисление по имени}
    начинаем с корня, самого внешнего синонима и
    заменяем его на определение (с помощью уравнения на правую часть 
    от знака равно), если на верху снова окажется синоним, мы опять 
    заменим его на определение и так пока на верху не появится 
    конструктор, тогда мы спустимся в дочерние деревья и будем
    повторять эту процедуру пока не дойдём до листьев дерева.
}

\smallskip

Посмотрим как каждая из стратегий будет редуцировать
наше выражение. Начнём со стратегии от листьев к корню (снизу-вверх):

\begin{code}
        add Zero two                    
-- видим два синонима add и two 
-- раскрываем two, ведь он находится ниже всех синонимов
=>      add Zero (Succ one)    
-- ниже появился ещё один синоним, раскроем и его
=>      add Zero (Succ (Succ zero))    
-- появился синоним zero раскроем его
=>      add Zero (Succ (Suсс Zero))
-- все узлы ниже содержат конструкторы, поднимаемся вверх до синонима
-- заменяем add на его правую часть
=>      foldNat Succ Zero (Succ (Succ Zero))  
-- самый нижний синоним foldNat, раскроем его
-- сопоставление с образцом проходит во втором уравнении для foldNat
=>      Succ (foldNat Succ Zero (Succ Zero))
-- снова раскрываем foldNat
=>      Succ (Succ (foldNat Zero Zero))
-- снова раскрываем foldNat, но на этот раз нам подходит
-- первое уравнение из определения foldNat
=>      Succ (Succ Zero)
-- синонимов больше нет можно вернуть значение
-- результат:
        Succ (Succ Zero)
\end{code}

В этой стратегии для каждой функции мы сначала вычисляем до конца
все аргументы, потом подставляем расшифрованные значения в
определение функции.

Теперь посмотрим на вычисление от корня к листьям (сверху-вниз):
    
\begin{code}
        add Zero two
-- видим два синонима add и two, начинаем с того, что ближе всех к корню
=>      foldNat Succ Zero two
-- теперь выше всех foldNat, раскроем его
\end{code}
    
Но для того чтобы раскрыть \In{foldNat} нам нужно узнать
какое уравнение выбрать для этого нам нужно понять какой
конструктор находится в корне у второго аргумента, если
это \In{Zero}, то мы выберем первое уравнение, а если это
\In{Succ}, то второе:

\begin{code}
-- в уравнении для foldNat видим декомпозицию по второму 
-- аргументу. Узнаем какой конструктор в корне у two
=>      foldNat Succ Zero (Succ one)
-- Это Succ нам нужно второе уравнение:
=>      Succ (foldNat Succ Zero one)
-- В корне м ыполучили конструктор, можем спуститься ниже.
-- Там мы видим foldNat, для того чтобы раскрыть его нам
-- снова нужно понять какой конструктор в корне у второго аргумента:
=>      Succ (foldNat Succ Zero (Succ zero))
-- Это опять Succ переходим ко второму уравнению для foldNat
=>      Succ (Succ (foldNat Succ Zero zero))
-- Снова раскрываем второй аргумент у foldNat
=>      Succ (Succ (foldNat Succ Zero Zero))
-- Ага это Zero, выбираем первое уравнение
=>      Succ (Succ Zero)
-- Синонимов больше нет можно вернуть значение
-- результат:
        Succ (Succ Zero)
\end{code}
   
В этой стратегии мы всегда раскрываем самый верхний уровень
выражения, можно представить как мы вытягиваем конструкторы
от корня по цепочке. У этих стратегий есть специальные имена:

\begin{itemize}
\item вычисление \emph{по значению} (call by value), когда 
    мы идём от листьев к корню.

\item вычисление \emph{по имени} (call by need), когда
    мы идём от корня к листьям.
\end{itemize}

\subsection{Преимущества и недостатки стратегий}

В чём преимущества, той и другой стратегии. 

\begin{quote}
Если выражение вычисляется полностью, первая стратегия
более эффективна по расходу памяти.
\end{quote}

\emph{Вычисляется полностью} означает все компоненты
выражения участвуют в вычислении. Например то выражении,
которое мы рассмотрели так подробно, вычисляется полностью.
Приведём пример выражения, при вычислении которого нужна лишь
часть аргументов, для этого определим функцию: 

\begin{code}
isZero :: Nat -> Bool
isZero Zero     = True
isZero _        = False
\end{code}

Она проверяет является ли нулём данное число, теперь представим
как будет вычисляться выражение, в той и другой стратегии:

\begin{code}
isZero (add Zero two)
\end{code}

Первая стратегия сначала вычислит все аргументы у \In{add}
потом расшифрует \In{add} и только в самом конце доберётся 
до \In{isZero}. На это уйдёт восемь шагов (семь 
на вычисление \In{add Zero two}).
В то время как вторая стратегия начнёт с \In{isZero}. 
Для вычисления \In{isZero} ей потребуется узнать какой конструктор в корне у
выражения \In{add Zero two}. Она узнает это за два шага. 
Итого три шага. Налицо экономия усилий. 

Почему вторая стратегия экономит память? Поскольку мы всегда
вычисляем аргументы функции, мы можем не хранить описания
в памяти а сразу при подстановке в функцию начинать редукцию.
Эту ситуацию можно понять на таком примере, посчитаем сумму чисел
от одного до четырёх с помощью такой функции:

\begin{code}
sum :: Int -> [Int] -> Int
sum []      res = res
sum (x:xs)  res = sum xs (res + x) 
\end{code}

Посмотрим на то как вычисляет первая стратегия, с учётом
того что мы вычисляем значения при подстановке:

\begin{code}
        sum [1,2,3,4] 0
=>      sum [2,3,4]   (0 + 1)    
=>      sum [2,3,4]   1
=>      sum [3,4]     (1 + 2)
=>      sum [3,4]     3
=>      sum [4]       (3+3)
=>      sum [4]       6
=>      sum []        (6+4)
=>      sum []        10
=>      10
\end{code}

Теперь посмотрим на вторую стратегию:

\begin{code}
        sum [1,2,3,4] 0
=>      sum [2,3,4]   0+1
=>      sum [3,4]     (0+1)+2
=>      sum [4]       ((0+1)+2)+3
=>      sum []        (((0+1)+2)+3)+4
=>      (((0+1)+2)+3)+4
=>      ((1+2)+3)+4
=>      (3+3)+4
=>      6+4
=>      10
\end{code}

А теперь представьте, что мы решили посчитать сумму чисел
от 1 до миллиона. Сколько вычислений нам придётся накопить!
В этом недостаток второй стратегии. 

Ещё одно преимущество первой стратегии -- предсказуемость
вычислений, мы можем легко понять как происходит вычисление.
Сначала вычисляются самые маленькие выражения, затем они подставляются
в выражения по-больше и так пока мы не очистим выражение от синонимов.
Вычисление по второй стратегии напоминает вытягивание конструкторов
из мутной воды выражения спинингом, никогда не знаешь какое выражение схватит
крючок первым. Может первым и знаешь, но вот кто пойдёт вторым-третьим 
не так ясно.

Но есть и ещё один недостаток, рассмотрим выражение:

\begin{code}
(\x -> add x (add x x)) (add Zero two)
\end{code}

Первая стратегия сначала редуцирует выражение \In{add Zero two}
в то время как вторая подставит это выражение в функцию
и утроит свою работу!

Но у второй стратегии есть одно очень веское преимущество,
она может вычислять больше выражений чем вторая. Определим 
значение бесконечность:

\begin{code}
infinity    :: Nat
infinity    = Succ infinity
\end{code}

Это рекурсивное определение, если мы попытаемся его распечатать
мы получим бесконечную последовательность \In{Succ}. Чем не 
бесконечность? Теперь посмотрим на выражение:

\begin{code}
isZero infinity
\end{code}

Первая стратегия захлебнётся, вычисляя аргумент функции \In{isZero},
в то время как вторая найдёт решение за два шага. 

Подведём итоги. Плюсы вычисления по значению:

\begin{itemize}
\item Эффективный расход памяти в том случае если все 
        составляющие выражения участвуют в вычислении.

\item Предсказуемость.

\item Она не может дублировать вычисления, как стратегия
        вычисления по имени.
\end{itemize}

Плюсы вычисления по имени:

\begin{itemize}
\item Меньше вычислений в том случае, если при вычислении выражения
    участвует лишь часть составляющих.


\item Большая выразительность. Мы можем вычислить больше значений.
\end{itemize}

Какую из них выбрать? В Haskell пошли по второму пути. Всё-таки
преимущество выразительности языка оказалось самым существенным.
Но для того чтобы избежать недостатков стратегии вычисления по имени
оно было модифицировано. Давайте посмотрим как.

\subsection{Вычисление по необходимости}

\Strategy{вычисление по необходимости}
\Strategy{ленивые вычисления}
Вернёмся к выражению: 

\begin{code}
(\x -> add x (add x x)) (add Zero two)
\end{code}

Проблема дублирования вычислений была решена с помощью графов.
Раньше мы проводили редукцию деревьев. Мы смотрели на дерево и
заменяли в некотором узле синоним на его определение, мы
разворачивали деревья, из деревьев получали новые деревья,
и так до итогового значения. В улучшенном алгоритме используются
направленные ациклические графы. Направленные графы, это
графы со стрелками, стрелки ведут от аргументов к функциям,
в которые эти аргументы подставляются. Ацикличность говорит об 
отсутствии циклов. Нет такой замкнутой последовательности стрелок,
по которой можно выйти из одной вершины и через несколько
вершин вернуться в неё же. С помощью графов мы выражаем
тот факт, что один и тот же аргумент функции может использоваться
сразу в нескольких местах выражения. 

Смысл в том, что мы запоминаем куда ведут аргументы
функции. Так из аргумента функции 
\verb!\!\In{x -> add x (add x x))} в правую часть
функции ведут три стрелки. При этом

\begin{quote}

Аргументы функции вычисляются не более одного раза.

\end{quote}

Эта стратегия выигрывает по числу редукций и у вычисления
по значению (за счёт того, что аргументы у функции могут
не вычисляться вообще, в то время как при вычислении по
значению аргументы вычисляются \emph{всегда}) и у вычисления 
по имени (за счёт отсутствия дублирования выражений при подстановке).

Такие вычисления называют вычислениями по необходимости
или ленивыми вычислениями. Основной слоган гласит:

\begin{quote}

Не откладывай на завтра то, что можно сделать послезавтра.
Делай как можно меньше и как можно позже.

\end{quote}

На то они и ленивые. Редукцию графов очень сложно реализовать.
Поэтому языков с ленивыми вычислениями очень мало. Ленивые вычисления
на ряду с классами типов являются основной отличительной чертой Haskell. 

\section{Реализация ленивых вычислений в ghc}

Основной компилятор для Haskell это ghc. Посмотрим
как ленивые вычисления реализованы в нём.
Нам потребуется узнать несколько новых терминов.

Если выражение не содержит синонимов, то оно находится
в 
\NF{нормальная форма}
\emph{нормальной форме} (normal form, NF), далее НФ. Выражение, 
у которого полностью вычислен хотя бы один конструктор,
находится в \emph{слабой заголовочной нормальной форме}
\NF{слабая заголовочная нормальная форма}
(weak-head normal form, WHNF), далее СЗНФ. Если выражение 
ещё не вычислялось, его называют \emph{отложенным}, 
в английской литературе используют загадочное слово
\In{thunk}, для краткости мы будем обозначать его решёткой
\verb!#!.

Итак выражение может находится в трёх состояниях:

\begin{itemize}
\item \In{НФ}, полностью вычислено.
\item \In{СЗНФ}, мы знаем один или более конструкторов от корня.
\item \verb!#! мы ещё не добрались до него, выражение содержит 
    лишь описание значения.
\end{itemize}

Запустим интерпретатор, поставим флаг \In{+s} подсчёта 
статистики вычислений и посчитаем сумму от одного до миллиарда,
(Ниже запись \In{1e9} обозначает единицу, которая умножена на число $10^9$):

\begin{code}
Prelude> :set +s
Prelude> let x = sum [1 .. 1e9]
(0.00 secs, 526724 bytes)
\end{code}

Чудеса, такая скорость! Теперь прибавим к результату единицу
и посмотрим на ответ:

\begin{code}
Prelude> x + 1
<interactive>: out of memory (requested 2097152 bytes)
\end{code}

Как же так, мы так быстро вычислили сумму 
миллиарда чисел, а теперь когда мы попытались прибавить
единицу нам не хватило памяти! В чём подвох?

Всё дело в ленивых вычислениях. В первом выражении
мы с помощью \In{let} определили новый синоним. На самом деле
ничего не вычислялось, интерпретатор сохраняет описание способа
вычисление и говорит \Quote{хорошо я сделаю это когда-нибудь потом}.
Это потом наступает, когда результат нам действительно нужен,
когда мы хотим на него посмотреть. Когда мы набрали \In{x + 1} 
и нажали \In{Enter}, вычислитель зачесался и начал работать, но 
к сожалению выяснилось, что он отложил на потом слишком много
дел. 

В терминологии ghc выражение \In{x} находится 
в состоянии \verb!#!. После нажатия \In{Enter} мы просим провести
редукцию и вычислить НФ. Редукция проводится по необходимости.
Единственное место, где такая необходимость возникает это
слева от знака равно в уравнениях, когда мы проводим 
сопоставление с образцом, или в \In{case}-выражениях.

Вспомним как мы вычисляли в самом начале выражение \In{add Zero two}
с помощью стратегии вычисления по имени (в данном случае вычисление
по имени и по необходимости совпадают, потому что мы нигде не 
дублируем вычисления). Каждый раз мы хотели вычислить самое
верхнее выражение, и каждый раз при расшифровке синонимов 
сталкивались с \emph{необходимостью} узнать какое уравнение 
нам выбрать. Для этого нам нужно было узнать какой конструктор 
находится \emph{в корне} одного из аргументов. Мы приводили
аргумент к СЗНФ но не более того, и далее проводили подстановку
значений в аргумент. 

Проведём это вычисление ещё раз, но теперь в терминах ghc. 
Мы будем проводить его \Quote{вслепую}. Мы будем обозначать все 
синонимы символом \verb!#!:

\begin{code}
вычислим:
        add   Zero two

=>      #                                   
=>      #   Zero #                                  -- приведём к НФ
=>      add Zero #
=>      foldNat Succ Zero #                         -- какое уравнение?
=>      foldNat Succ Zero two
=>      foldNat Succ Zero (Succ #)                  -- выбираем 2 уравнение
=>      Succ (foldNat Succ Zero #)                  -- какое уравнение?
=>      Succ (foldNat Succ Zero one)
=>      Succ (foldNat Succ Zero (Succ #))           -- выбираем 2 уравнение
=>      Succ (Succ (foldNat Succ Zero #))           -- какое уравнение?
=>      Succ (Succ (foldNat Succ Zero zero))
=>      Succ (Succ (foldNat Succ Zero Zero))        -- выбираем 1 уравнение
=>      Succ (Succ (foldNat Succ Zero Zero))
=>      Succ (Succ Zero)                            -- НФ
\end{code}


Каждый \verb!#! содержит ссылку на способ вычисление
или синоним. Видите, мы расшифровываем значения аргументов 
лишь для того, чтобы узнать какое уравнение выбрать.


Такая экономия усилий позволяет определять все возможные
значения и затем выбирать из них лишь, те что нужны.
Вычислитель пропустит всё лишнее. 


\subsubsection{Ленивый поиск корней уравнения}

Приведём пример. Поиск корней уравнения с помощью метода
неподвижной точки.
У нас есть функция \In{f :: a -> a}, и нам нужно найти 
решение уравнения:

\begin{code}
f x = x
\end{code}

Можно начать с какого-нибудь стартового значения, и подставлять,
подставлять, подставлять его в \In{f} до тех пор, пока значение
не перестанет изменяться. Так мы найдём решение. 

\begin{code}
xх1 = f x0
x2 = f x1
x3 = f x2
...
до тех пор пока abs (x[N] - x[N-1]) <= eps
\end{code}

Первое наблюдение: функция принимает не произвольные значения,
а те для которых имеет смысл операции: минус, поиск абсолютного
значения и сравнение на больще/меньше. Тип нашей функции:

\begin{code}
f :: (Ord a, Num a) => a -> a
\end{code}

Ленивые вычисления позволяют нам отделить шаг генерации
решений, от шага проверки сходимости. Сначала мы сделаем
список всех подстановок функции \In{f}, а затем найдём
в этом списке два соседних элемента расстояние между которыми 
достаточно мало. Итак первый шаг, генерируем всю
последовательность:

\begin{code}
xNs = iterate f x0
\end{code}

Мы воспользовались стандартной функцией \In{iterate} из
\In{Prelude}. Теперь ищем два соседних числа:


\begin{code}
converge :: (Ord a, Num a) => a -> [a] -> a
converge eps (a:b:xs) 
    | abs (a - b) <= eps    = a
    | otherwise             = converge eps (b:xs)
\end{code}

Поскольку список бесконечный мы можем не проверять
случаи для пустого списка. Итоговое решение:

\begin{code}
roots :: (Ord a, Num a) => a -> a -> (a -> a) -> a
roots eps x0 f = converge eps $ iterate f x0
\end{code}

За счёт ленивых вычислений функции
\In{converge} и \In{iterate} работают синхронно.
Функция \In{converge} запрашивает новое значение
и \In{iterate} передаёт его, но только одно!
Найдём решение какого-нибудь уравнения. Запустим интерпретатор.
Мы ленимся и не создаём новый модуль для такой \Quote{большой}
функции. Определяем её сразу в интерпретаторе.


\begin{code}
Prelude> let converge eps (a:b:xs) = if abs (a-b)<=eps then a else converge eps (b:xs)
Prelude> let roots eps x0 f = converge eps $ iterate f x0
\end{code}

Найдём корень уравнения:

\[  x (x-2) = 0 \]
\[  x^2 - 2 x = 0 \]
\[  \frac{1}{2} x^2 = x \]

\begin{code}
Prelude> roots 0.001 5 (\x -> x*x/2)
\end{code}

Метод завис, остаётся только нажать \In{ctrl+c}
для остановки. На самом деле есть одно условие для
сходимости метода. Метод сойдётся, если модуль 
производной функции \In{f} меньше единицы. Иначе есть
возможность, что мы будем бесконечно генерировать новые подстановки.
Вычислим производную нашей функции:

\[  \frac{d}{dx} \frac{1}{2} x^2 = x \]

Нам следует ожидать решения в интервале от минус единицы до единицы:

\begin{code}
Prelude> roots 0.001 0.5 (\x -> x*x/2)
3.0517578125e-5
Prelude> (\x -> x*x/2) $ roots 0.001 0.5 (\x -> x*x/2)
4.656612873077393e-10
\end{code}

Мы нашли решение, корень равен нулю. В этой записи \In{Ne-5}
означает $N \cdot 10^{-5}$


\subsection{Форточка в мир вычислений по значению}

А что нам делать, если нам всё-таки хочется вычислить
сумму миллиарда чисел?
Специально для таких случаев в Haskell предусмотрена 
функция \In{seq}. Она имеет тип:

\begin{code}
seq :: a -> b -> b
\end{code}

Функция \In{seq}, говорит вычислителю: сначала приведи
мой первый аргумент к СЗНФ, а затем верни второй.
Корень проблемы заключается в том, что у нас есть не только
наши собственные типы, но и встроенные типы, такие как 
целые и действительные числа. Для чисел редукция выражений, означает
вычисление реального численного значения. Поскольку у нас нет 
конструкторов чисел, мы не можем вычислитель заставить их 
редуцировать заранее.

Для решения этой проблемы была придумана функция \In{seq}.
Давайте определим функцию \In{sum'}, которая
будет сразу вычислять значение.

\begin{code}
sum' :: Num a => [a] -> a
sum' = iter 0 
    where iter res []        = res
          iter res (a:as)    = let res' = res + a
                               in  res' `seq` iter res' as 
\end{code}

Сохраним результат в отдельном модуле \In{Strict.hs} и
попробуем теперь вычислить значение, придётся подождать:

\begin{code}
Strict> sum' [1 .. 1e9]
\end{code}

И мы ждём, и ждём, и ждём.


\subsection{Компиляция модулей}

И мы ждём и ждём и ждём. Но переполнения памяти не происходит.
Это хорошо. Но давайте прервём вычисления. Нажмём \In{ctrl+c}.
Функция \In{sum'} вычисляется, но вычисляется очень медленно.
Мы можем существенно ускорить её, если \emph{скомпилируем}
модуль \In{Strict}. До сих пор мы всегда интерпретировали модули. 
В процессе компиляции функция оптимизируется специальным
образом, она может стать на порядок быстрее. 

Для того чтобы скомпилировать модуль нужно переключиться
в его текущую директорию и вызвать компилятор \In{ghc} с
флагом  \verb!--!\In{make}:

\begin{code}
ghc --make Strict
\end{code}

Появились два файла \In{Strict.hi} и \In{Strict.o}. Первый
файл называется интерфейсным он описывает какие в модуле 
определения, а второй файл называется объектным. Он содержит
скомпилированный код модуля. Теперь мы можем загрузить 
модуль \In{Strict} в интерпретатор и сравнить выполнение двух функций:


\begin{code}
Strict> sum' [1 .. 1e6]
5.000005e11
(0.00 secs, 89133484 bytes)
Strict> sum [1 .. 1e6]
5.000005e11
(0.57 secs, 142563064 bytes)
\end{code}

Обратите внимание на прирост скорости. Умение понимать
в каких случаях стоит ограничить лень очень важно. 
И в программах на Haskell тоже. 

Также компилировать модули можно из интерпретатора.
Для этого воспользуемся командой \In{:!}, она 
выполняет системные команды в интерпретаторе \In{ghci}:

\begin{code}
Strict> :! ghc --make Strict
[1 of 1] Compiling Strict           ( Strict.hs, Strict.o )
\end{code}

Отметим наличие специальной функции применения, которая
просит перед применением привести аргумент к СЗНФ, эта 
функция определена в \In{Prelude}:

\begin{code}
($!) :: (a -> b) -> a -> b
 f $! a = a `seq` f a
\end{code}

С этой функцией мы модем определить функцию \In{sum} так:

\begin{code}
sum' :: Num a => [a] -> a
sum' = iter 0 
    where iter res []        = res
          iter res (a:as)    = flip iter as $! res + a
\end{code}


\subsection{Функции с хвостовой рекурсией}

Определим функцию, которая не будет лениться при
вычислении произведения чисел, мы назовём её \In{product'}:

\begin{code}
product' :: Num a => [a] -> a
product' = iter 1
    where iter res []        = res
          iter res (a:as)    = let res' = res * a
                               in  res' `seq` iter res' as 
\end{code}

Смотрите функция \In{sum} изменилась лишь в двух местах. Это
говорит о том, что пора задуматься о том, а нет ли такой
общей функции, которая включает в себя и то и другое поведение.
Такая функция есть и называется она \In{foldl'}, вот её определение:

\begin{code}
foldl' :: (a -> b -> a) -> a -> [b] -> a
foldl' op init = iter init
    where iter res []        = res
          iter res (a:as)    = let res' = res `op` a
                               in  res' `seq` iter res' as 
\end{code}

Мы вынесли в аргументы функции бинарную операцию и 
начальное значение. Всё остальное осталось прежним.
Эта функция живёт в модуле \In{Data.List}. Теперь
мы можем определить функции \In{sum'} и \In{prod'}:

\begin{code}
sum'        = foldl' (+) 0
product'    = foldl' (*) 1
\end{code}


Также в \In{Prelude} определена функция \In{foldl}. 
Она накапливает значения в аргументе, но без принуждения вычислять 
промежуточные результаты:

\begin{code}
foldl :: (a -> b -> a) -> a -> [b] -> a
foldl op init = iter init
    where iter res []        = res
          iter res (a:as)    = iter (res `op` a) as 
\end{code}

Такая функция называется функцией с \emph{хвостовой рекурсией}
(tail-recursive function). Рекурсия хвостовая тогда, когда 
рекурсивный вызов функции является последним действием, которое 
выполняется в функции. Посмотрите на второе уравнение функции
\In{iter}. Мы вызываем функцию \In{iter} рекурсивно последним
делом. В языках с вычислением по значению часто хвостовая рекурсия
имеет преимущество за счёт экономии памяти (тот момент который
мы обсуждали в самом начале). Но как видно из этого раздела
в ленивых языках это не так. Библиотечная функция \In{sum}
будет накапливать выражения перед вычислением с риском
исчерпать всю доступную память, потому что она
определена через \In{foldl}.

\subsection{Тонкости применения seq}

Хочу подчеркнуть, что функция \In{seq} не вычисляет 
свой первый аргумент полностью. Первый аргумент не приводится
к нормальной форме. Мы лишь просим вычислитель узнать какой 
конструктор находится в корне у данного выражения.
Например в выражении \In{isZero $! infinity} знак
\In{$!} ничем не отличается от простого применения мы
и так будем приводить аргумент \In{infinity} к СЗНФ,
когда нам понадобится узнать какое из уравнений для 
\In{isZero} выбрать, ведь в аргументе функции 
есть сопоставление с образцом.

Рассмотрим пример. Определим такой тип данных:

\begin{code}
data TheDouble = TheDouble Double
    deriving (Show, Eq)

instance Num TheDouble where
    (+) = inTheDouble2 (+)
    (-) = inTheDouble2 (-)
    (*) = inTheDouble2 (*)

    abs = inTheDouble1 abs
    signum = inTheDouble1 signum
    fromInteger = TheDouble . fromInteger 

inTheDouble1 f  (TheDouble a)                = TheDouble $ f a
inTheDouble2 op (TheDouble a) (TheDouble b)  = TheDouble $ op a b
\end{code}

Теперь посчитаем сумму чисел с помощью нашей функции \In{sum'}
и сравним результат с обычной функцией \In{sum} и с вычислениями
\In{sum'} на просто \In{Double}. Сохраним тип \In{TheDouble}
в модуле \In{Strict}, скомпилируем модуль для скорости и
загрузим в интерпретатор:

\begin{code}
Prelude Strict> :! ghc --make Strict
[1 of 1] Compiling Strict           ( Strict.hs, Strict.o )
Prelude Strict> :l Strict
Ok, modules loaded: Strict.
(0.00 secs, 576936 bytes)
\end{code}

Теперь посмотрим на вычисления:

\begin{code}
Prelude Strict> sum' [1::Double .. 1e6]
5.000005e11
(0.05 secs, 88609416 bytes)
Prelude Strict> sum [1::Double .. 1e6]
5.000005e11
(0.56 secs, 142566848 bytes)
Prelude Strict> sum' $ map TheDouble [1::Double .. 1e6]
TheDouble 5.000005e11
(0.52 secs, 237439212 bytes)
\end{code}

Смотрите после того как мы завернули все числа
в \In{TheDouble} вычисления стали проходить с такой же
скоростью, что и в случае обычной функции \In{sum}.
Это происходит потому, что теперь численный тип сидит
в обёртке, когда мы попробуем вычислить СЗНФ в функции
\In{seq}, мы не узнаем ничего нового кроме конструктора обёртки:

\begin{code}
вычислим СЗНФ:
        TheDouble 1 + TheDouble 2

=>      inTheDouble2 (+) (TheDouble 1) (TheDouble 2)
=>      TheDouble $ (TheDouble 1) + (TheDouble 2)
=>      TheDouble ((TheDouble 1) + (TheDouble 2))
-- мы узнали, что в корне сидит конструктор TheDouble,
-- дальше нам идти не нужно, вернём значение:
        TheDouble #
\end{code}

И теперь суммы по прежнему накапливаются, но в 
конструкторе \In{TheDouble}. Кстати на этом примере
можно понять разницу между \In{data} и \In{newtype},
если мы определим тип \In{TheDouble} через \In{newtype}
вычисления будут происходить быстрее.

Посмотрим на один типичный пример. Вычисление среднего
для списка чисел. Среднее равно сумме всех элементов
списка, разделённой на длину списка. Для того
чтобы вычислить значение за один проход мы будем
одновременно вычислять и сумму элементов и значение
длины. Также мы понимаем, что нам не нужно откладывать
вычисления, воспользуемся функцией \In{foldl'}:

\begin{code}
mean :: [Double] -> Double
mean = division . foldl' count (0, 0)
    where count  (sum, leng) a = (sum+a, leng+1)
          division (sum, leng) = sum / fromIntegral leng
\end{code}

Проходим по списку, копим сумму в первом элементе пары и
длину во втором. В самом конце делим первый элемент на второй.
Обратите внимание на функцию \In{fromIntegral} она преобразует
значения из целых чисел, в какие-нибудь другие из класса \In{Num}.
Сохраним это определение в модуле \In{Strict} скомпилируем
модуль и загрузим в интерпретатор, не забудьте импортировать
модуль \In{Data.List}, он нужен для функции \In{foldl'}. 
Посмотрим, что у нас получилось:


\begin{code}
Prelude Strict> mean [1 .. 1e7]
5000000.5
(49.65 secs, 2476557164 bytes)
\end{code}

Получилось очень медленно, странно ведь порядок этой функции
должен быть таким же что и у \In{sum'}. Посмотрим на скорость \In{sum'}:

\begin{code}
Prelude Strict> sum' [1 .. 1e7]
5.0000005e13
(0.50 secs, 881855740 bytes)
\end{code}

В 100 раз быстрее. Теперь представьте, что у нас 10 таких функций
как \In{mean} они разбросаны по всему коду и делают своё чёрное 
ленивое дело. Причина такого поведения кроется в том, что мы
опять завернули значение в другой тип, на этот раз в пару.
Когда вычислитель дойдёт до \In{seq}, он остановится на 
выражении \verb!(#,#)! вместо двух чисел. Он вновь будет 
накапливать отложенные вычисления, а не значения.

Перепишем \In{mean}, теперь мы будем вычислять значения
пары по отдельности и попросим вычислитель привести
к СЗНФ каждое из них перед вычислением итогового значения:

\begin{code}
mean' :: [Double] -> Double
mean' = division . iter (0, 0)
    where iter res          []      = res
          iter (sum, leng)  (a:as)  = 
                let s = sum  + a
                    l = leng + 1
                in  s `seq` l `seq` iter (s, l) as
          
          division (sum, leng) = sum / fromIntegral leng
\end{code}

Такой вот монстр. Функция \In{seq} право ассоциативна
поэтому скобки будут группироваться в нужном порядке.
В этом определении мы просим вычислитель привести
к СЗНФ \emph{числа}, а не пары чисел, как в прошлой версии.
Для чисел СЗНФ совпадает с НФ, и всё должно пройти гладко,
но сохраним это определение и проверим результат:

\begin{code}
Prelude Strict> :! ghc --make Strict
[1 of 1] Compiling Strict           ( Strict.hs, Strict.o )
Prelude Strict> :load Strict
Ok, modules loaded: Strict.
(0.00 secs, 0 bytes)
Prelude Strict> mean' [1 .. 1e7]
5000000.5
(0.65 secs, 1083157384 bytes)
\end{code}

Получилось! Скорость чуть хуже чем у \In{sum'}, но не в сто раз.

\subsection{Взрывная декомпозиция}

В ghc у нас есть возможность не лазить в мир 
вычислений по значению через форточку, пробираясь через заросли
\In{seq}, а пройти через ворота, возможно прихватив телегу
значений. Для этого существуют так называемые \emph{взрывные образцы}
(bang patterns).

\subsubsection{Расширения языка}

Для того чтобы у нас появилась возможность пользоваться ими
нам нужно поместить в самый верх модуля такую фразу:

\begin{code}
{-# LANGUAGE BangPatterns #-}
\end{code}

Эта запись активирует расширение языка с именем \In{BangPatterns}.
Ядро языка Haskell фиксировано стандартом, но каждый разработчик
компилятора может вносить свои дополнения. Они подключаются 
через директиву \In{LANGUAGE}:

\begin{code}
{-# LANGUAGE 
        Расширение1, 
        Расширение2, 
        Расширение3 #-}
\end{code}

Мы заключаем директиву в специальные комментарии с решёткой,
говорим \In{LANGUAGE} а затем через запятую перечисляем
имена расширений, которые нам понадобятся. Расширения активны 
только в рамках данного модуля. Например если мы импортируем
функции из модуля, в котором включены расширения, то эти
расширения не распространяются дальше на другие модули. 

\subsubsection{Ещё один способ сказать seq}

Посмотрим на функцию, которая использует взрывные образцы:

\begin{code}
iter (!sum, !leng) a = (step + a, leng + 1)
\end{code}

В декомпозиции пары перед переменными у нас появились 
восклицательные знаки. Они говорят вычислителю о том, 
чтобы он так уж и быть сделал ещё одно усилие и заглянул в корень
значений переменных, которые были переданы в эту функцию. 

Вычислитель говорит ладно-ладно сделаю. А там числа! И
получается, что они не накапливаются. С помощью
взрывных образцов мы можем переписать функцию \In{mean'} 
через \In{foldl'}, а не выписывать её целиком:

\begin{code}
mean'' :: [Double] -> Double
mean'' = division . foldl' iter (0, 0)
    where iter (!sum, !leng) a = (sum  + a, leng + 1)
          division (sum, leng) = sum / fromIntegral leng
\end{code}

Проверим в интерпретаторе

\begin{code}
*Strict> :! ghc --make Strict
[1 of 1] Compiling Strict           ( Strict.hs, Strict.o )
*Strict> :l Strict
Ok, modules loaded: Strict.
(0.00 secs, 581304 bytes)
Prelude Strict> mean'' [1 .. 1e7]
5000000.5
(0.78 secs, 1412862488 bytes)
Prelude Strict> mean' [1 .. 1e7]
5000000.5
(0.65 secs, 1082640204 bytes)
\end{code}

Функция работает чуть медленнее, чем исходная версия, но не
сильно.

\subsubsection{Кто взрывается?}

Почему образцы называются взрывными? И кто взрывается? 
Давайте проведём несколько тестовых взрывов в интерпретаторе:

\begin{code}
Prelude Strict> undefined
*** Exception: Prelude.undefined
Prelude Strict> error "Here is the Bang"
*** Exception: Here is the Bang
\end{code}

Взрыв это остановка программы с ошибкой во время вычислений.
Программа прошла проверку типов, но внезапно останавливается
в процессе вычислений, возможно с кратким сообщением.
Подорвать программу можно с помощью встроенных функций
\In{undefined} и \In{error}, также можно забыть рассмотреть
какой-нибудь случай при декомпозиции аргументов и программа
подорвётся сама. Например так:

\begin{code}

Prelude Strict> let bangList [] = True
(0.00 secs, 527636 bytes)
Prelude Strict> bangList [1,2,3]
*** Exception: <interactive>:1:4-21: Non-exhaustive patterns in function bangList
Prelude Strict> bangList []
True
(0.00 secs, 0 bytes)
\end{code}

В Haskell для обозначения взрыва используется специальное
значение, оно называется \emph{основание} или \In{дно} 
в английском так и пишут bottom или символом $\bot$. Создать это значение 
можно с помощью функции \In{undefined}. Считается, что это
значение может быть любого типа. 

При этом работает правило:

\begin{quote}
Если в функции \emph{возникает} необходимость привести
взрывное значение к СЗНФ, то вся функция возвращает 
взрывное значение.
\end{quote}

Слово \Quote{возникает} выделено, потому что такой возможности
может и не произойти, благодаря ленивым вычислениям. 
Наша функция может быть заминирована в аргументах. Но ленивый
вычислитель просто никогда не узнает о них. Возможно
в процессе вычислений окажется, что эти аргументы не нужны.
Посмотрим на несколько примеров:

\begin{code}
Prelude> const 1 undefined
1
Prelude> let maybeBang x = if sin x > 0 then x else undefined
Prelude> maybeBang 1
1.0
Prelude> maybeBang 2
2.0
Prelude> maybeBang 3
3.0
Prelude> maybeBang 4
*** Exception: Prelude.undefined
Prelude> maybeBang 5
*** Exception: Prelude.undefined
\end{code}

В функции \In{const} второй аргумент не нужен для вычислений
поэтому взрыва не произошло.
Функция \In{maybeBang} заминирована, но за счёт природной
лени \In{if}-выражений взрыв происходит не всегда. 

Функции, которые гарантированно взрываются, если 
в них передать \In{undefined}, называют \emph{строгими} (strict).
Различают строгость по аргументам. Например функция
\In{const} строгая по первому аргументу, но нестрогая по второму.
Функция \In{tail} строгая. Функция \In{id} строгая, потому что
она возвращает \In{undefined}, если ей передать \In{undefined}.

Есть тонкость связанная с частичным применением. Посмотрим
на определение функции логического и:

\begin{code}
(&&) :: Bool -> Bool -> Bool
(&&) False _ = False
(&&) True  x = x
\end{code}

Эта функция вернёт нестрогую функцию из первого 
уравнения но строгую из второго. Это видно если переписать 
это определение так:

\begin{code}
(&&) :: Bool -> Bool -> Bool
(&&) False = const False
(&&) True  = id
\end{code}

Итак кто взрывается мы выяснили. Теперь посмотрим почему
взрывными называют образцы. Взрывной образец превращает
нестрогую функцию в строгую. Например определим функцию:

\begin{code}
constBang :: a -> b -> a
constBang a !b = a
\end{code}

Эта функция совпадает с функцией \In{const}, единственное
отличие заключается во взрывном образце. Теперь посмотрим 
взорвётся ли она:

\begin{code}
Prelude Strict> constBang 1 undefined
*** Exception: Prelude.undefined
\end{code}

Взрыв произошёл, функция стала строгой. Если приглядеться
к этой функции, то можно заметить, что это функция \In{seq}.
Взрывным образцом мы заставляем вычислитель зайти в заминированный
аргумент. Но вычислитель зайдёт лишь на уровень ниже, обратите
внимание на то, что это выражение не взорвётся:

\begin{code}
Prelude Strict> constBang 1 (Just undefined)
1
\end{code}


\subsubsection{seq по умолчанию}

С помощью взрывных образцов мы можем создавать типы
данных, в которых приведение к СЗНФ проводится всегда
на уровень ниже чем обычно. Для этого в определении 
типа нужно поставить восклицательный знак перед тем 
подтипом, который будет приводиться к СЗНФ, если
вычислитель дошёл до конструктора. 

Например изменим наш тип \In{TheDouble} так:

\begin{code}
data TheDouble = TheDouble !Double
\end{code}

Появился восклицательный знак перед подтипом \In{Double}.
Теперь, если вычислитель получит где-нибудь выражение 
\In{(TheDouble}~\verb!#!\In{)} он обязательно раскроет и аргумент, но также
только на один уровень! В данном случае этого достаточно, 
проверим в интерпретаторе:

\begin{code}
Prelude Strict> sum' $ map TheDouble [1 .. 1e7]
TheDouble 5.0000005e13
(1.04 secs, 1683465592 bytes)
\end{code}

Получилось в два раза медленнее чем с обычными числами.
Видимо это время ушло на заворачивание-разворачивание 
чисел. 

Давайте убедимся в том, что значение подтипа раскрывается
только на один уровень, для этого создадим два типа:

\begin{code}
data Strict a = Strict !a
data Lazy   a = Lazy a
\end{code}

Теперь поэкспериментируем с подрывом функции \In{seq}, 
мы будем передавать заминированное значение первым аргументом,
но с разными обёртками. Функция \In{seq} заставит вычислитель
привести к СЗНФ первый аргумент перед возвращением второго.
Первой командой мы отключаем подсчёт статистики, чтобы она нам
не мешалась. Сначала проверяем подорвётся ли \In{seq} на
обычном значении \In{undefined}. 

\begin{code}
Prelude Strict> :unset +s
Prelude Strict> seq undefined "Hello"
"*** Exception: Prelude.undefined
\end{code}


Как и ожидалось \In{seq}
подорвался. Спрячем бомбу в ленивый конструктор:

\begin{code}
Prelude Strict> seq (Lazy undefined) "Hello"
"Hello"
\end{code}

Значение вычислено, никто не пострадал.
Теперь попробуем пронести бомбу мимо \In{seq} 
в строгом конструкторе:

\begin{code}
Prelude Strict> seq (Strict undefined) "Hello"
"*** Exception: Prelude.undefined
\end{code}


Взрыв! Восклицательный знак в определении конструктора
привёл к тому, что после того как вычислитель получил
\In{(Strict}~\verb!#!\In{)} ему пришлось на свою погибель
заглянуть глубже. Но попробуем завернуть значение 
в строгом конструкторе в ленивый конструктор: 

\begin{code}
Prelude Strict> seq (Strict $ Lazy undefined) "Hello"
"Hello"
\end{code}

Получили значение. Напоследок убедимся в том, что цепочка
строгих конструкторов приводит к взрыву:

\begin{code}
Prelude Strict> seq (Strict $ Strict $ Strict $ Strict undefined) "Hello"
"*** Exception: Prelude.undefined
\end{code}


\section{Краткое содержание}

В этой главе мы узнали о том как происходят вычисления
в Haskell. Мы узнали, что они ленивые. Всё вычисляется
как можно позже и как можно меньше. Такие вычисления
называются вычислениями по необходимости.

Также мы узнали о вычислениях по значению и вычислениях по имени.

\begin{itemize}
\item В \emph{вычислениях по значению} редукция проводится от 
        листьев дерева выражения к корню
\item В \emph{вычислениях по имени} редукция проводится от корня 
        дерева выражения к листьям.
\end{itemize}

Вычисление по необходимости является улучшением 
вычисления по имени. Мы не дублируем выражения
во время применения. Все аргументы функции вычисляются
не более одного раза.

Мы познакомились с терминологией процесса вычислений.
Выражение может находится в \emph{нормальной форме}. Это значит
что оно вычислено. Может находится в \emph{слабой заголовочной
нормальной форме}. Это значит, что мы знаем хотя бы один 
конструктор в корне выражения. Также возможно выражение 
ещё не вычислялось, тогда оно является \emph{отложенным} (thunk).

Суть ленивых вычислений заключается в том, что они
происходят синхронно. Если у нас есть 
композиция двух функций:

\[ g\ (f\ x) \]

Внутренняя функция \In{f} не начнёт вычисления до тех
пор пока значения не понадобятся внешней функции \In{g}.
О последствиях этого мы остановимся подробнее в следующей главе.
Значения могут потребоваться при сопоставлении с образцом.
Когда мы хотим узнать какое из уравнений нам выбрать.

Иногда ленивые вычисления не эффективны по расходу памяти. 
Это происходит когда выражение состоит из большого числа
подвыражений, которые будут вычислены в любом случае.
В Haskell у нас есть способы борьбы с ленью. 
Это функция \In{seq} и взрывные образцы. 

Функция \In{seq}:

\begin{code}
seq :: a -> b -> b
\end{code}

Сначала приводит к слабой заголовочной форме свой первый
аргумент, а затем возвращает второй. Взрывные образцы
выполняют те же функции, но они используются в декомпозиции 
аргументов или в объявлении типа. 

Также мы узнали как компилируются модули в \In{ghc}. Это делается
с помощью команды:

\begin{code}
ghc --make ИмяМодуля
\end{code}

Модули можно компилировать и из интерпретатора, выполнив команду

\begin{code}
Prelude>:! ghc --make ИмяМодуля
\end{code}

\section{Упражнения}

\begin{itemize}

\item Потренируйтесь в понимании того как происходят
        ленивые вычисления. Вычислите на бумаге 
        следующие выражения (если это возможно):


\begin{itemize}
\item 
\begin{code}
sum $ take 3 $ filter (odd . fst) $ 
    zip [1 ..] [1, undefined, 2, undefined, 3, undefined, undefined]
\end{code}

\item \In{take 2 $ foldr (+) 0 $ map Succ $ repeat Zero}
\item \In{take 2 $ foldl (+) 0 $ map Succ $ repeat Zero}
\end{itemize}

\item Посмотрите на такую функцию вычисления суммы
        всех чётных и нечётных чисел в списке. 

\begin{code}
sum2 :: [Int] -> (Int, Int)
sum2 []     c = c
sum2 (x:xs) c = sum2 xs (tick x c)

tick :: Int -> (Int, Int) -> (Int, Int)
tick x (c0, c1) | even x    = (c0, c1 + 1)
                | otherwise = (c0 + 1, c1)
\end{code} 

    Эта функция очень медленная. Кто-то слишком много ленится.
    Узнайте кто, и ускорьте функцию.
    
\end{itemize}
